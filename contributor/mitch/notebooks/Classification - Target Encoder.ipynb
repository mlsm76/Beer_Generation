{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Units and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import category_encoders as ce\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "# Classification\n",
    "import sklearn.linear_model\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (26,39,40,42,47,48,50,55,56,58,63,64,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96540 entries, 0 to 96539\n",
      "Columns: 106 entries, Batch_Style to Flag\n",
      "dtypes: float64(55), int64(1), object(50)\n",
      "memory usage: 78.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Style</th>\n",
       "      <th>Category</th>\n",
       "      <th>Batch_size_liters</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color_levibonds</th>\n",
       "      <th>mashph</th>\n",
       "      <th>Base Malt Amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Adjunct1Unit</th>\n",
       "      <th>Adjunct2Num</th>\n",
       "      <th>Adjunct2Unit</th>\n",
       "      <th>Adjunct3Num</th>\n",
       "      <th>Adjunct3Unit</th>\n",
       "      <th>Adjunct4Num</th>\n",
       "      <th>Adjunct4Unit</th>\n",
       "      <th>Adjunct5Num</th>\n",
       "      <th>Adjunct5Unit</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Standard/Ordinary Bitter</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.008</td>\n",
       "      <td>4.31</td>\n",
       "      <td>25.98</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Belgian Dubbel</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.027</td>\n",
       "      <td>11.83</td>\n",
       "      <td>13.47</td>\n",
       "      <td>9.20</td>\n",
       "      <td>5.35</td>\n",
       "      <td>300.000</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partial Mash</td>\n",
       "      <td>Robust Porter</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.077</td>\n",
       "      <td>1.015</td>\n",
       "      <td>8.11</td>\n",
       "      <td>14.06</td>\n",
       "      <td>25.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.012</td>\n",
       "      <td>6.76</td>\n",
       "      <td>33.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Blonde Ale</td>\n",
       "      <td>1589.9</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.012</td>\n",
       "      <td>5.28</td>\n",
       "      <td>17.47</td>\n",
       "      <td>4.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.476</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96535</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Mixed-Fermentation Sour Beer</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.011</td>\n",
       "      <td>5.11</td>\n",
       "      <td>9.59</td>\n",
       "      <td>5.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96536</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.010</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>tsp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96537</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Berliner Weisse</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.722</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96538</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.06</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96539</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Experimental Beer</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.023</td>\n",
       "      <td>6.10</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93473 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Batch_Style                       Category  Batch_size_liters     og  \\\n",
       "0          All Grain       Standard/Ordinary Bitter              480.0  1.041   \n",
       "1          All Grain                 Belgian Dubbel             1800.0  1.117   \n",
       "2       Partial Mash                  Robust Porter               20.8  1.077   \n",
       "3          All Grain                   American IPA              200.0  1.064   \n",
       "4          All Grain                     Blonde Ale             1589.9  1.053   \n",
       "...              ...                            ...                ...    ...   \n",
       "96535        Extract   Mixed-Fermentation Sour Beer               20.8  1.050   \n",
       "96536      All Grain                      Weissbier               19.9  1.051   \n",
       "96537           BIAB                Berliner Weisse               20.8  1.053   \n",
       "96538           BIAB                      Weissbier               50.0  1.051   \n",
       "96539      All Grain              Experimental Beer               20.0  1.069   \n",
       "\n",
       "          fg    abv    ibu  color_levibonds  mashph  Base Malt Amount  ...  \\\n",
       "0      1.008   4.31  25.98             3.00     NaN            75.000  ...   \n",
       "1      1.027  11.83  13.47             9.20    5.35           300.000  ...   \n",
       "2      1.015   8.11  14.06            25.81     NaN             0.454  ...   \n",
       "3      1.012   6.76  33.79            13.53     NaN            43.000  ...   \n",
       "4      1.012   5.28  17.47             4.08     NaN           249.476  ...   \n",
       "...      ...    ...    ...              ...     ...               ...  ...   \n",
       "96535  1.011   5.11   9.59             5.62     NaN             2.268  ...   \n",
       "96536  1.010   5.46   1.30             3.67    5.35             2.268  ...   \n",
       "96537  1.013   5.24   6.83             3.81     NaN             2.722  ...   \n",
       "96538  1.013   5.06   6.49             3.22     NaN             4.000  ...   \n",
       "96539  1.023   6.10  13.99             3.89    5.40             3.300  ...   \n",
       "\n",
       "      Adjunct1Unit  Adjunct2Num  Adjunct2Unit  Adjunct3Num  Adjunct3Unit  \\\n",
       "0              NaN          NaN           NaN          NaN           NaN   \n",
       "1                g          NaN           NaN          NaN           NaN   \n",
       "2              NaN          NaN           NaN          NaN           NaN   \n",
       "3              NaN          NaN           NaN          NaN           NaN   \n",
       "4              NaN          NaN           NaN          NaN           NaN   \n",
       "...            ...          ...           ...          ...           ...   \n",
       "96535          NaN          NaN           NaN          NaN           NaN   \n",
       "96536          tsp          NaN           NaN          NaN           NaN   \n",
       "96537          NaN          NaN           NaN          NaN           NaN   \n",
       "96538          NaN          NaN           NaN          NaN           NaN   \n",
       "96539          NaN          NaN           NaN          NaN           NaN   \n",
       "\n",
       "      Adjunct4Num  Adjunct4Unit  Adjunct5Num  Adjunct5Unit      Flag  \n",
       "0             NaN           NaN          NaN           NaN    Metric  \n",
       "1             NaN           NaN          NaN           NaN    Metric  \n",
       "2             NaN           NaN          NaN           NaN  Imperial  \n",
       "3             NaN           NaN          NaN           NaN    Metric  \n",
       "4             NaN           NaN          NaN           NaN  Imperial  \n",
       "...           ...           ...          ...           ...       ...  \n",
       "96535         NaN           NaN          NaN           NaN  Imperial  \n",
       "96536         NaN           NaN          NaN           NaN  Imperial  \n",
       "96537         NaN           NaN          NaN           NaN  Imperial  \n",
       "96538         NaN           NaN          NaN           NaN    Metric  \n",
       "96539         NaN           NaN          NaN           NaN    Metric  \n",
       "\n",
       "[93473 rows x 106 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data and drop index\n",
    "beer_df = pd.read_csv('beer_df_for_classification.csv',index_col=[0])\n",
    "beer_df.info()\n",
    "beer_df.head()\n",
    "beer_df.dropna(subset=['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_df = beer_df[beer_df.Flag == 'Imperial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing it at this time helps to avoid overfitting or picking the wrong architecture based on bias\n",
    "#function for test set and validation set creation:\n",
    "def split_train_val_test(beer_df,validation_ratio, test_ratio):\n",
    "    np.random.seed(33)\n",
    "    shuffled_indices = np.random.permutation(len(beer_df))  #shuffles the dataset\n",
    "    validation_set_size = int(len(beer_df) * validation_ratio) #calculates validation set size based on ratio   \n",
    "    test_set_size = int(len(beer_df) * test_ratio) #calculates test size based on ratio\n",
    "    val_indices = shuffled_indices[:validation_set_size]\n",
    "    test_indices = shuffled_indices[:test_set_size] #selects test set and from incdices\n",
    "    train_indices = shuffled_indices[(test_set_size+validation_set_size):] #assigns the rest to training\n",
    "    return beer_df.iloc[train_indices], beer_df.iloc[val_indices], beer_df.iloc[test_indices] #returns two different dfs for test and train\n",
    "    \n",
    "#Using the function\n",
    "train_set, validation_set, test_set = split_train_val_test(beer_df, 0.15,0.10) #75% used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44232 8846 5897\n"
     ]
    }
   ],
   "source": [
    "#check that it worked\n",
    "print(len(train_set), len(validation_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "#validation_set.to_csv('beer_data_val.csv')\n",
    "#train_set.to_csv('beer_data_train.csv')\n",
    "#test_set.to_csv('beer_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,normalize, Normalizer,LabelEncoder, OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder\n",
    "from category_encoders.count import CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42967\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.dropna(subset=['Category'])\n",
    "X = train_set.drop(['Category'],axis=1)\n",
    "y = train_set[\"Category\"].copy()\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding is the same as it was for clustering, except the target variables (Category) will be label encoded this time\n",
    "#variables with over 50% NaN/Missing values are categorized as \"highna\"\n",
    "num_highna=['mashph','hop2amount','hop2alpha','hop2time','hop2ibu',\n",
    "            'hop2percent','hop3amount','hop3alpha','hop3time',\n",
    "            'hop3ibu','hop3percent','hop4amount','hop4alpha',\n",
    "            'hop4time','hop4ibu','hop4percent','hop5amount',\n",
    "            'hop5alpha','hop5time','hop5ibu','hop5percent',\n",
    "            'Adjunct1Num','Adjunct2Num','Adjunct3Num','Adjunct4Num','Adjunct5Num']\n",
    "num_lowna = ['Batch_size_liters', 'og', 'fg', 'abv', 'ibu', 'color_levibonds',\n",
    "       'Base Malt Amount', 'BasePPG', 'BaseColor', 'BasePercentage',\n",
    "       'SpecialtyMalt1Amount', 'SpecialtyMalt1PPG', 'SpecialtyMalt1Color',\n",
    "       'SpecialtyMalt1Percentage', 'SpecialtyMalt2Amount', 'SpecialtyMalt2PPG',\n",
    "       'SpecialtyMalt2Color', 'SpecialtyMalt2Percentage',\n",
    "       'SpecialtyMalt3Amount', 'SpecialtyMalt3PPG', 'SpecialtyMalt3Color',\n",
    "       'SpecialtyMalt3Percentage','hop1amount','hop1time','hop1ibu','hop1percent','hop1alpha','Attenuation', 'LowTemp', 'HighTemp']\n",
    "cat_highna = ['hop2name', 'hop2type', 'hop2timing', 'hop3name',\n",
    "       'hop3type', 'hop3timing', 'hop4name', 'hop4type', 'hop4timing',\n",
    "       'hop5name', 'hop5type', 'hop5timing', 'Adjunct1Amount', 'Adjunct1Name', 'Adjunct1Type',\n",
    "       'Adjunct1Timing', 'Adjunct2Amount', 'Adjunct2Name', 'Adjunct2Type',\n",
    "       'Adjunct2Timing', 'Adjunct3Amount', 'Adjunct3Name', 'Adjunct3Type',\n",
    "       'Adjunct3Timing', 'Adjunct4Amount', 'Adjunct4Name', 'Adjunct4Type',\n",
    "       'Adjunct4Timing', 'Adjunct5Amount', 'Adjunct5Name', 'Adjunct5Type',\n",
    "       'Adjunct5Timing', 'Adjunct1Unit', 'Adjunct2Unit', 'Adjunct3Unit',\n",
    "       'Adjunct4Unit', 'Adjunct5Unit']\n",
    "cat_lowna = ['Batch_Style', 'Base Malt', 'SpecialtyMalt1Name',\n",
    "       'SpecialtyMalt2Name', 'SpecialtyMalt3Name', 'hop1name', 'hop1type',\n",
    "       'hop1timing', 'YeastStrain', 'Flocculation',\n",
    "       'Starter?', 'Flag']\n",
    "target = ['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles numerical values, imputing the mean and scaling (standard instead of minmax since it handles outliers better)\n",
    "num_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"mean\")),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "num_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"constant\",fill_value=0)),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "#handles categorical values, imputing the most frequent and onehot encoding\n",
    "cat_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")),\n",
    "        ('encoder', TargetEncoder(handle_missing='return_nan',min_samples_leaf=100,smoothing=10)),\n",
    "        ('standardizer', RobustScaler())\n",
    "       \n",
    "    ])\n",
    "cat_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"most_frequent\")),\n",
    "        ('encoder', TargetEncoder(handle_missing='return_nan',min_samples_leaf=100,smoothing=10)),\n",
    "        ('standardizer', RobustScaler())\n",
    "    ])\n",
    "#pulls together two pipelines\n",
    "pre_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_lowna\", num_pipeline_lowna, num_lowna),\n",
    "        (\"num_highna\", num_pipeline_highna,num_highna),\n",
    "        (\"cat_lowna\", cat_pipeline_lowna, cat_lowna),\n",
    "        (\"cat_highna\", cat_pipeline_highna, cat_highna),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encodes the target variable\n",
    "le = LabelEncoder()\n",
    "label_encoder = le.fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "beer_prepared = pre_pipeline.fit_transform(X,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42967"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying out a few base models before we get to hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "style_predictions = lin_reg.predict(beer_prepared)\n",
    "lin_mse = mean_squared_error(y, style_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_predictions = tree_reg.predict(beer_prepared)\n",
    "tree_mse = mean_squared_error(y, style_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, beer_prepared, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display scores of various models using cross validation\n",
    "def display_scores(scores):\n",
    "     print(\"Scores:\", scores)\n",
    "     print(\"Mean:\", scores.mean())\n",
    "     print(\"Standard deviation:\", scores.std())\n",
    "display_scores(-scores)\n",
    "#this one is massively overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "#not great but not as overfit as the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_reg = RandomForestClassifier()\n",
    "forest_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the base models for now in case I need em\n",
    "import joblib\n",
    "joblib.dump(lin_reg, \"base_lin_reg.pkl\")\n",
    "joblib.dump(tree_reg, \"base_decision_tree.pkl\")\n",
    "joblib.dump(forest_reg, \"base_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'max_features': [20, 40, 60, 80],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [20, 30, 40],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [20, 40, 60, 80]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [20, 30, 40]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=60, n_estimators=30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01186451, 0.04066941, 0.01809807, 0.06186122, 0.0817024 ,\n",
       "       0.07891454, 0.01614501, 0.00936395, 0.01412867, 0.0241285 ,\n",
       "       0.01387679, 0.01350853, 0.02011798, 0.02225436, 0.01133653,\n",
       "       0.01213452, 0.01498031, 0.01697597, 0.00870791, 0.00946596,\n",
       "       0.01190827, 0.01351986, 0.01291701, 0.00778263, 0.02617946,\n",
       "       0.01844661, 0.01871563, 0.01738201, 0.02241697, 0.01862489,\n",
       "       0.00743269, 0.00482201, 0.02548963, 0.00301598, 0.00392168,\n",
       "       0.00501606, 0.00185632, 0.00304434, 0.00206429, 0.00151047,\n",
       "       0.00298606, 0.00131348, 0.00159583, 0.00147449, 0.00100502,\n",
       "       0.0020511 , 0.00077453, 0.00117427, 0.00102311, 0.00049164,\n",
       "       0.00131831, 0.0020343 , 0.00179349, 0.00157865, 0.00077436,\n",
       "       0.00066236, 0.00582226, 0.02069114, 0.0220463 , 0.01767569,\n",
       "       0.01299906, 0.02312819, 0.00267201, 0.00177265, 0.05777723,\n",
       "       0.01424155, 0.00349348, 0.        , 0.02221909, 0.00143352,\n",
       "       0.00206731, 0.00561202, 0.0008579 , 0.00129125, 0.0016958 ,\n",
       "       0.0004002 , 0.00074223, 0.00103224, 0.00033549, 0.00052526,\n",
       "       0.00232489, 0.00182951, 0.00080818, 0.00135011, 0.00217626,\n",
       "       0.00225856, 0.00124956, 0.00138166, 0.0017793 , 0.0018328 ,\n",
       "       0.00116554, 0.00132372, 0.0007246 , 0.00095151, 0.00066243,\n",
       "       0.00065699, 0.00115336, 0.00062885, 0.00058766, 0.00056886,\n",
       "       0.0017744 , 0.00136289, 0.00144257, 0.00058326, 0.00053771])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225.339457567804 47.17350376607406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "test_set = test_set.dropna(subset=['Category'])\n",
    "X_test = test_set.drop('Category',axis=1)\n",
    "y_test = test_set['Category'].copy()\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "X_test_prepared = pre_pipeline.transform(X_test)\n",
    "\n",
    "model_preds = best_model.predict(X_test_prepared)\n",
    "\n",
    "model_mse = mean_squared_error(y_test, model_preds)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "\n",
    "print(model_mse,model_rmse) #rmse = 38.65, mse = 1493.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4983377077865267"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model_preds, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match up feature importances with actual names of features\n",
    "targetencode_cols_low = list(pre_pipeline.named_transformers_['cat_lowna'].named_steps['encoder'].get_feature_names())\n",
    "targetencode_cols_high = list(pre_pipeline.named_transformers_['cat_highna'].named_steps['encoder'].get_feature_names())\n",
    "numeric_list = list(num_lowna)\n",
    "numeric_highna_list = list(num_highna)\n",
    "numeric_list.extend(num_highna)\n",
    "numeric_list.extend(targetencode_cols_high)\n",
    "numeric_list.extend(targetencode_cols_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batch_size_liters',\n",
       " 'og',\n",
       " 'fg',\n",
       " 'abv',\n",
       " 'ibu',\n",
       " 'color_levibonds',\n",
       " 'Base Malt Amount',\n",
       " 'BasePPG',\n",
       " 'BaseColor',\n",
       " 'BasePercentage',\n",
       " 'SpecialtyMalt1Amount',\n",
       " 'SpecialtyMalt1PPG',\n",
       " 'SpecialtyMalt1Color',\n",
       " 'SpecialtyMalt1Percentage',\n",
       " 'SpecialtyMalt2Amount',\n",
       " 'SpecialtyMalt2PPG',\n",
       " 'SpecialtyMalt2Color',\n",
       " 'SpecialtyMalt2Percentage',\n",
       " 'SpecialtyMalt3Amount',\n",
       " 'SpecialtyMalt3PPG',\n",
       " 'SpecialtyMalt3Color',\n",
       " 'SpecialtyMalt3Percentage',\n",
       " 'hop1amount',\n",
       " 'hop1time',\n",
       " 'hop1ibu',\n",
       " 'hop1percent',\n",
       " 'hop1alpha',\n",
       " 'Attenuation',\n",
       " 'LowTemp',\n",
       " 'HighTemp',\n",
       " 'mashph',\n",
       " 'hop2amount',\n",
       " 'hop2alpha',\n",
       " 'hop2time',\n",
       " 'hop2ibu',\n",
       " 'hop2percent',\n",
       " 'hop3amount',\n",
       " 'hop3alpha',\n",
       " 'hop3time',\n",
       " 'hop3ibu',\n",
       " 'hop3percent',\n",
       " 'hop4amount',\n",
       " 'hop4alpha',\n",
       " 'hop4time',\n",
       " 'hop4ibu',\n",
       " 'hop4percent',\n",
       " 'hop5amount',\n",
       " 'hop5alpha',\n",
       " 'hop5time',\n",
       " 'hop5ibu',\n",
       " 'hop5percent',\n",
       " 'Adjunct1Num',\n",
       " 'Adjunct2Num',\n",
       " 'Adjunct3Num',\n",
       " 'Adjunct4Num',\n",
       " 'Adjunct5Num',\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
