{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Units and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import category_encoders as ce\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "# Classification\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (26,39,40,42,47,48,50,55,56,58,63,64,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96540 entries, 0 to 96539\n",
      "Columns: 106 entries, Batch_Style to Flag\n",
      "dtypes: float64(55), int64(1), object(50)\n",
      "memory usage: 78.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Style</th>\n",
       "      <th>Category</th>\n",
       "      <th>Batch_size_liters</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color_levibonds</th>\n",
       "      <th>mashph</th>\n",
       "      <th>Base Malt Amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Adjunct1Unit</th>\n",
       "      <th>Adjunct2Num</th>\n",
       "      <th>Adjunct2Unit</th>\n",
       "      <th>Adjunct3Num</th>\n",
       "      <th>Adjunct3Unit</th>\n",
       "      <th>Adjunct4Num</th>\n",
       "      <th>Adjunct4Unit</th>\n",
       "      <th>Adjunct5Num</th>\n",
       "      <th>Adjunct5Unit</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Standard/Ordinary Bitter</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.008</td>\n",
       "      <td>4.31</td>\n",
       "      <td>25.98</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Belgian Dubbel</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.027</td>\n",
       "      <td>11.83</td>\n",
       "      <td>13.47</td>\n",
       "      <td>9.20</td>\n",
       "      <td>5.35</td>\n",
       "      <td>300.000</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partial Mash</td>\n",
       "      <td>Robust Porter</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.077</td>\n",
       "      <td>1.015</td>\n",
       "      <td>8.11</td>\n",
       "      <td>14.06</td>\n",
       "      <td>25.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.012</td>\n",
       "      <td>6.76</td>\n",
       "      <td>33.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Blonde Ale</td>\n",
       "      <td>1589.9</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.012</td>\n",
       "      <td>5.28</td>\n",
       "      <td>17.47</td>\n",
       "      <td>4.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.476</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96535</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Mixed-Fermentation Sour Beer</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.011</td>\n",
       "      <td>5.11</td>\n",
       "      <td>9.59</td>\n",
       "      <td>5.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96536</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.010</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>tsp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96537</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Berliner Weisse</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.722</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96538</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.06</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96539</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Experimental Beer</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.023</td>\n",
       "      <td>6.10</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93473 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Batch_Style                       Category  Batch_size_liters     og  \\\n",
       "0          All Grain       Standard/Ordinary Bitter              480.0  1.041   \n",
       "1          All Grain                 Belgian Dubbel             1800.0  1.117   \n",
       "2       Partial Mash                  Robust Porter               20.8  1.077   \n",
       "3          All Grain                   American IPA              200.0  1.064   \n",
       "4          All Grain                     Blonde Ale             1589.9  1.053   \n",
       "...              ...                            ...                ...    ...   \n",
       "96535        Extract   Mixed-Fermentation Sour Beer               20.8  1.050   \n",
       "96536      All Grain                      Weissbier               19.9  1.051   \n",
       "96537           BIAB                Berliner Weisse               20.8  1.053   \n",
       "96538           BIAB                      Weissbier               50.0  1.051   \n",
       "96539      All Grain              Experimental Beer               20.0  1.069   \n",
       "\n",
       "          fg    abv    ibu  color_levibonds  mashph  Base Malt Amount  ...  \\\n",
       "0      1.008   4.31  25.98             3.00     NaN            75.000  ...   \n",
       "1      1.027  11.83  13.47             9.20    5.35           300.000  ...   \n",
       "2      1.015   8.11  14.06            25.81     NaN             0.454  ...   \n",
       "3      1.012   6.76  33.79            13.53     NaN            43.000  ...   \n",
       "4      1.012   5.28  17.47             4.08     NaN           249.476  ...   \n",
       "...      ...    ...    ...              ...     ...               ...  ...   \n",
       "96535  1.011   5.11   9.59             5.62     NaN             2.268  ...   \n",
       "96536  1.010   5.46   1.30             3.67    5.35             2.268  ...   \n",
       "96537  1.013   5.24   6.83             3.81     NaN             2.722  ...   \n",
       "96538  1.013   5.06   6.49             3.22     NaN             4.000  ...   \n",
       "96539  1.023   6.10  13.99             3.89    5.40             3.300  ...   \n",
       "\n",
       "      Adjunct1Unit  Adjunct2Num  Adjunct2Unit  Adjunct3Num  Adjunct3Unit  \\\n",
       "0              NaN          NaN           NaN          NaN           NaN   \n",
       "1                g          NaN           NaN          NaN           NaN   \n",
       "2              NaN          NaN           NaN          NaN           NaN   \n",
       "3              NaN          NaN           NaN          NaN           NaN   \n",
       "4              NaN          NaN           NaN          NaN           NaN   \n",
       "...            ...          ...           ...          ...           ...   \n",
       "96535          NaN          NaN           NaN          NaN           NaN   \n",
       "96536          tsp          NaN           NaN          NaN           NaN   \n",
       "96537          NaN          NaN           NaN          NaN           NaN   \n",
       "96538          NaN          NaN           NaN          NaN           NaN   \n",
       "96539          NaN          NaN           NaN          NaN           NaN   \n",
       "\n",
       "      Adjunct4Num  Adjunct4Unit  Adjunct5Num  Adjunct5Unit      Flag  \n",
       "0             NaN           NaN          NaN           NaN    Metric  \n",
       "1             NaN           NaN          NaN           NaN    Metric  \n",
       "2             NaN           NaN          NaN           NaN  Imperial  \n",
       "3             NaN           NaN          NaN           NaN    Metric  \n",
       "4             NaN           NaN          NaN           NaN  Imperial  \n",
       "...           ...           ...          ...           ...       ...  \n",
       "96535         NaN           NaN          NaN           NaN  Imperial  \n",
       "96536         NaN           NaN          NaN           NaN  Imperial  \n",
       "96537         NaN           NaN          NaN           NaN  Imperial  \n",
       "96538         NaN           NaN          NaN           NaN    Metric  \n",
       "96539         NaN           NaN          NaN           NaN    Metric  \n",
       "\n",
       "[93473 rows x 106 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data and drop index\n",
    "beer_df = pd.read_csv('beer_df_for_classification.csv',index_col=[0])\n",
    "beer_df.info()\n",
    "beer_df.head()\n",
    "beer_df.dropna(subset=['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing it at this time helps to avoid overfitting or picking the wrong architecture based on bias\n",
    "#function for test set and validation set creation:\n",
    "def split_train_val_test(beer_df,validation_ratio, test_ratio):\n",
    "    np.random.seed(33)\n",
    "    shuffled_indices = np.random.permutation(len(beer_df))  #shuffles the dataset\n",
    "    validation_set_size = int(len(beer_df) * validation_ratio) #calculates validation set size based on ratio   \n",
    "    test_set_size = int(len(beer_df) * test_ratio) #calculates test size based on ratio\n",
    "    val_indices = shuffled_indices[:validation_set_size]\n",
    "    test_indices = shuffled_indices[:test_set_size] #selects test set and from incdices\n",
    "    train_indices = shuffled_indices[(test_set_size+validation_set_size):] #assigns the rest to training\n",
    "    return beer_df.iloc[train_indices], beer_df.iloc[val_indices], beer_df.iloc[test_indices] #returns two different dfs for test and train\n",
    "    \n",
    "#Using the function\n",
    "train_set, validation_set, test_set = split_train_val_test(beer_df, 0.15,0.10) #75% used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72405 14481 9654\n"
     ]
    }
   ],
   "source": [
    "#check that it worked\n",
    "print(len(train_set), len(validation_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "validation_set.to_csv('beer_data_val.csv')\n",
    "train_set.to_csv('beer_data_train.csv')\n",
    "test_set.to_csv('beer_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,normalize, Normalizer,LabelEncoder, OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder\n",
    "from category_encoders.count import CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70057\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.dropna(subset=['Category'])\n",
    "X = train_set.drop(['Category'],axis=1)\n",
    "y = train_set[\"Category\"].copy()\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding is the same as it was for clustering, except the target variables (Category) will be label encoded this time\n",
    "#variables with over 50% NaN/Missing values are categorized as \"highna\"\n",
    "num_highna=['mashph','hop2amount','hop2alpha','hop2time','hop2ibu',\n",
    "            'hop2percent','hop3amount','hop3alpha','hop3time',\n",
    "            'hop3ibu','hop3percent','hop4amount','hop4alpha',\n",
    "            'hop4time','hop4ibu','hop4percent','hop5amount',\n",
    "            'hop5alpha','hop5time','hop5ibu','hop5percent',\n",
    "            'Adjunct1Num','Adjunct2Num','Adjunct3Num','Adjunct4Num','Adjunct5Num']\n",
    "num_lowna = ['Batch_size_liters', 'og', 'fg', 'abv', 'ibu', 'color_levibonds',\n",
    "       'Base Malt Amount', 'BasePPG', 'BaseColor', 'BasePercentage',\n",
    "       'SpecialtyMalt1Amount', 'SpecialtyMalt1PPG', 'SpecialtyMalt1Color',\n",
    "       'SpecialtyMalt1Percentage', 'SpecialtyMalt2Amount', 'SpecialtyMalt2PPG',\n",
    "       'SpecialtyMalt2Color', 'SpecialtyMalt2Percentage',\n",
    "       'SpecialtyMalt3Amount', 'SpecialtyMalt3PPG', 'SpecialtyMalt3Color',\n",
    "       'SpecialtyMalt3Percentage','hop1amount','hop1time','hop1ibu','hop1percent','hop1alpha','Attenuation', 'LowTemp', 'HighTemp']\n",
    "cat_highna = ['hop2name', 'hop2type', 'hop2timing', 'hop3name',\n",
    "       'hop3type', 'hop3timing', 'hop4name', 'hop4type', 'hop4timing',\n",
    "       'hop5name', 'hop5type', 'hop5timing', 'Adjunct1Amount', 'Adjunct1Name', 'Adjunct1Type',\n",
    "       'Adjunct1Timing', 'Adjunct2Amount', 'Adjunct2Name', 'Adjunct2Type',\n",
    "       'Adjunct2Timing', 'Adjunct3Amount', 'Adjunct3Name', 'Adjunct3Type',\n",
    "       'Adjunct3Timing', 'Adjunct4Amount', 'Adjunct4Name', 'Adjunct4Type',\n",
    "       'Adjunct4Timing', 'Adjunct5Amount', 'Adjunct5Name', 'Adjunct5Type',\n",
    "       'Adjunct5Timing', 'Adjunct1Unit', 'Adjunct2Unit', 'Adjunct3Unit',\n",
    "       'Adjunct4Unit', 'Adjunct5Unit']\n",
    "cat_lowna = ['Batch_Style', 'Base Malt', 'SpecialtyMalt1Name',\n",
    "       'SpecialtyMalt2Name', 'SpecialtyMalt3Name', 'hop1name', 'hop1type',\n",
    "       'hop1timing', 'YeastStrain', 'Flocculation',\n",
    "       'Starter?', 'Flag']\n",
    "target = ['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles numerical values, imputing the mean and scaling (standard instead of minmax since it handles outliers better)\n",
    "num_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"mean\")),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "num_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"constant\",fill_value=0)),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "#handles categorical values, imputing the most frequent and onehot encoding\n",
    "cat_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")),\n",
    "        ('encoder', CountEncoder(handle_missing='return_nan',min_group_size=.01,combine_min_nan_groups=True))        \n",
    "    ])\n",
    "cat_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"most_frequent\")),\n",
    "        ('encoder', CountEncoder(handle_missing='return_nan',min_group_size=0.01,combine_min_nan_groups=True))        \n",
    "    ])\n",
    "#pulls together two pipelines\n",
    "pre_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_lowna\", num_pipeline_lowna, num_lowna),\n",
    "        (\"num_highna\", num_pipeline_highna,num_highna),\n",
    "        (\"cat_lowna\", cat_pipeline_lowna, cat_lowna),\n",
    "        (\"cat_highna\", cat_pipeline_highna, cat_highna),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_prepared = pre_pipeline.fit_transform(X,y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70057"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encodes the target variable\n",
    "le = LabelEncoder()\n",
    "label_encoder = le.fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out a few base models before we get to hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.679339335426235"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "style_predictions = lin_reg.predict(beer_prepared)\n",
    "lin_mse = mean_squared_error(y, style_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22149503629031086"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_predictions = tree_reg.predict(beer_prepared)\n",
    "tree_mse = mean_squared_error(y, style_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, beer_prepared, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [3102.95849986 3101.64130745 3135.84170711 3082.49657436 3137.79346275\n",
      " 3060.6427348  3157.6328861  3217.63286938 3040.40885082 3143.33747323]\n",
      "Mean: 3118.0386365856893\n",
      "Standard deviation: 48.90208963402913\n"
     ]
    }
   ],
   "source": [
    "#function to display scores of various models using cross validation\n",
    "def display_scores(scores):\n",
    "     print(\"Scores:\", scores)\n",
    "     print(\"Mean:\", scores.mean())\n",
    "     print(\"Standard deviation:\", scores.std())\n",
    "display_scores(-scores)\n",
    "#this one is massively overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [45.14907883 45.90436669 45.74295962 46.43475091 45.93237839 46.28127798\n",
      " 45.56010737 57.49578184 45.32224708 45.73563177]\n",
      "Mean: 46.955858049424464\n",
      "Standard deviation: 3.5328611612597003\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "#not great but not as overfit as the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [38.55063278 38.93790681 39.04571738 39.03800903 39.60860038 39.23259552\n",
      " 39.31792234 39.16232581 38.31573292 39.15573902]\n",
      "Mean: 39.0365182004156\n",
      "Standard deviation: 0.35219041651964755\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_random_forest.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the base models for now in case I need em\n",
    "import joblib\n",
    "joblib.dump(lin_reg, \"base_lin_reg.pkl\")\n",
    "joblib.dump(tree_reg, \"base_decision_tree.pkl\")\n",
    "joblib.dump(forest_reg, \"base_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [20, 40, 60, 80],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [20, 30, 40],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [20, 40, 60, 80]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [20, 30, 40]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=80, n_estimators=30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01129865, 0.02393912, 0.0217164 , 0.04209988, 0.06725438,\n",
       "       0.06782862, 0.01359407, 0.00802323, 0.01583586, 0.01981394,\n",
       "       0.0125456 , 0.01092339, 0.01801823, 0.02884332, 0.00992036,\n",
       "       0.01100057, 0.0146859 , 0.01540337, 0.0084272 , 0.00825411,\n",
       "       0.01132119, 0.01252496, 0.01176747, 0.00778917, 0.02191702,\n",
       "       0.01823223, 0.03617183, 0.01953898, 0.01694921, 0.01621279,\n",
       "       0.00555174, 0.02427809, 0.12160741, 0.0018533 , 0.00252076,\n",
       "       0.00767189, 0.00142348, 0.00268808, 0.00114114, 0.0011023 ,\n",
       "       0.00163192, 0.00082827, 0.00089569, 0.00066122, 0.00054225,\n",
       "       0.00088379, 0.00042221, 0.00070634, 0.00045296, 0.00032163,\n",
       "       0.00068141, 0.00164373, 0.00121495, 0.00139566, 0.00057512,\n",
       "       0.00054608, 0.0033616 , 0.01922439, 0.01656111, 0.01338476,\n",
       "       0.01031598, 0.01869007, 0.00217378, 0.00128852, 0.0672018 ,\n",
       "       0.01840479, 0.00209656, 0.00092139, 0.00372015, 0.00065366,\n",
       "       0.0095333 , 0.00155102, 0.0004307 , 0.00058883, 0.00110903,\n",
       "       0.00019505, 0.00034566, 0.00063109, 0.00021867, 0.00026409,\n",
       "       0.00148814, 0.00145296, 0.00023042, 0.00080885, 0.00140192,\n",
       "       0.00161231, 0.00059303, 0.0007296 , 0.00136414, 0.00171823,\n",
       "       0.00072119, 0.00088476, 0.00060461, 0.00101022, 0.00049215,\n",
       "       0.00052626, 0.00091188, 0.0007503 , 0.00031133, 0.00036868,\n",
       "       0.00107293, 0.00101996, 0.00093533, 0.00038158, 0.00065075])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-d53940be82c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#match up feature importances with actual names of features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcat_lowna_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cat_lowna\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcat_lowna_attribs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_pipeline_lowna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcat_higna_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cat_highna\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcat_highna_attribs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_highna_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "#match up feature importances with actual names of features\n",
    "cat_lowna_encoder = pre_pipeline.named_transformers_[\"cat_lowna\"]\n",
    "cat_lowna_attribs = list(cat_pipeline_lowna.get_feature_names())\n",
    "cat_higna_encoder = pre_pipeline.named_transformers_[\"cat_highna\"]\n",
    "cat_highna_attribs = list(cat_highna_encoder.categories_[0])\n",
    "attributes = num_highna + num_lowna + cat_lowna_attribs + cat_highna_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
