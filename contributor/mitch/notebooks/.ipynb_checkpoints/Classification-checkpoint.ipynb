{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import category_encoders as ce\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "# Classification\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (21,26,39,40,42,47,48,50,55,56,58,63,64,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93472 entries, 0 to 93471\n",
      "Columns: 107 entries, Unnamed: 0 to Flag\n",
      "dtypes: float64(55), int64(2), object(50)\n",
      "memory usage: 76.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Style</th>\n",
       "      <th>Category</th>\n",
       "      <th>Batch_size_liters</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color_levibonds</th>\n",
       "      <th>mashph</th>\n",
       "      <th>Base Malt Amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Adjunct1Unit</th>\n",
       "      <th>Adjunct2Num</th>\n",
       "      <th>Adjunct2Unit</th>\n",
       "      <th>Adjunct3Num</th>\n",
       "      <th>Adjunct3Unit</th>\n",
       "      <th>Adjunct4Num</th>\n",
       "      <th>Adjunct4Unit</th>\n",
       "      <th>Adjunct5Num</th>\n",
       "      <th>Adjunct5Unit</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.074</td>\n",
       "      <td>1.019</td>\n",
       "      <td>7.26</td>\n",
       "      <td>106.79</td>\n",
       "      <td>12.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.930</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>39.7</td>\n",
       "      <td>1.067</td>\n",
       "      <td>1.011</td>\n",
       "      <td>7.27</td>\n",
       "      <td>76.96</td>\n",
       "      <td>7.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>39.7</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.014</td>\n",
       "      <td>7.03</td>\n",
       "      <td>76.28</td>\n",
       "      <td>9.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>English IPA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.059</td>\n",
       "      <td>1.014</td>\n",
       "      <td>5.91</td>\n",
       "      <td>59.98</td>\n",
       "      <td>7.95</td>\n",
       "      <td>5.40</td>\n",
       "      <td>2.500</td>\n",
       "      <td>...</td>\n",
       "      <td>tsp</td>\n",
       "      <td>0.75</td>\n",
       "      <td>tsp</td>\n",
       "      <td>1.25</td>\n",
       "      <td>tsp</td>\n",
       "      <td>1.68</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>International Pale Lager</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.010</td>\n",
       "      <td>5.38</td>\n",
       "      <td>45.73</td>\n",
       "      <td>3.45</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.588</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93467</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Berliner Weisse</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.031</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.42</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1.497</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93468</th>\n",
       "      <td>Extract</td>\n",
       "      <td>British Golden Ale</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1.012</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.52</td>\n",
       "      <td>35.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93469</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Cream Ale</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.054</td>\n",
       "      <td>1.015</td>\n",
       "      <td>5.10</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2.67</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.680</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>1.00</td>\n",
       "      <td>g</td>\n",
       "      <td>0.50</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93470</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Special/Best/Premium Bitter</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.009</td>\n",
       "      <td>4.10</td>\n",
       "      <td>19.67</td>\n",
       "      <td>4.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93471</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Biere de Garde</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1.020</td>\n",
       "      <td>6.03</td>\n",
       "      <td>33.77</td>\n",
       "      <td>18.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.361</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93472 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Batch_Style                      Category  Batch_size_liters     og  \\\n",
       "0       All Grain                  American IPA               32.0  1.074   \n",
       "1       All Grain                  American IPA               39.7  1.067   \n",
       "2       All Grain                  American IPA               39.7  1.068   \n",
       "3       All Grain                   English IPA               19.0  1.059   \n",
       "4       All Grain      International Pale Lager               17.0  1.051   \n",
       "...           ...                           ...                ...    ...   \n",
       "93467     Extract               Berliner Weisse               18.9  1.031   \n",
       "93468     Extract            British Golden Ale                3.8  1.104   \n",
       "93469     Extract                     Cream Ale                8.5  1.054   \n",
       "93470     Extract   Special/Best/Premium Bitter               27.5  1.040   \n",
       "93471     Extract                Biere de Garde                9.5  1.066   \n",
       "\n",
       "          fg    abv     ibu  color_levibonds  mashph  Base Malt Amount  ...  \\\n",
       "0      1.019   7.26  106.79            12.45     NaN             8.930  ...   \n",
       "1      1.011   7.27   76.96             7.97     NaN            10.886  ...   \n",
       "2      1.014   7.03   76.28             9.97     NaN            10.886  ...   \n",
       "3      1.014   5.91   59.98             7.95    5.40             2.500  ...   \n",
       "4      1.010   5.38   45.73             3.45    5.75             1.588  ...   \n",
       "...      ...    ...     ...              ...     ...               ...  ...   \n",
       "93467  1.005   3.42    6.51             1.63    5.80             1.497  ...   \n",
       "93468  1.012  12.00   18.52            35.96     NaN             0.454  ...   \n",
       "93469  1.015   5.10   13.56             2.67    4.26             0.680  ...   \n",
       "93470  1.009   4.10   19.67             4.18     NaN             3.000  ...   \n",
       "93471  1.020   6.03   33.77            18.02     NaN             1.361  ...   \n",
       "\n",
       "      Adjunct1Unit  Adjunct2Num  Adjunct2Unit  Adjunct3Num  Adjunct3Unit  \\\n",
       "0              NaN          NaN           NaN          NaN           NaN   \n",
       "1              NaN          NaN           NaN          NaN           NaN   \n",
       "2              NaN          NaN           NaN          NaN           NaN   \n",
       "3              tsp         0.75           tsp         1.25           tsp   \n",
       "4              NaN          NaN           NaN          NaN           NaN   \n",
       "...            ...          ...           ...          ...           ...   \n",
       "93467          NaN          NaN           NaN          NaN           NaN   \n",
       "93468          NaN          NaN           NaN          NaN           NaN   \n",
       "93469            g         1.00             g         0.50             g   \n",
       "93470          NaN          NaN           NaN          NaN           NaN   \n",
       "93471          NaN          NaN           NaN          NaN           NaN   \n",
       "\n",
       "      Adjunct4Num  Adjunct4Unit  Adjunct5Num  Adjunct5Unit      Flag  \n",
       "0             NaN           NaN          NaN           NaN    Metric  \n",
       "1             NaN           NaN          NaN           NaN  Imperial  \n",
       "2             NaN           NaN          NaN           NaN  Imperial  \n",
       "3            1.68            ml          NaN           NaN    Metric  \n",
       "4             NaN           NaN          NaN           NaN  Imperial  \n",
       "...           ...           ...          ...           ...       ...  \n",
       "93467         NaN           NaN          NaN           NaN  Imperial  \n",
       "93468         NaN           NaN          NaN           NaN  Imperial  \n",
       "93469         NaN           NaN          NaN           NaN  Imperial  \n",
       "93470         NaN           NaN          NaN           NaN    Metric  \n",
       "93471         NaN           NaN          NaN           NaN  Imperial  \n",
       "\n",
       "[93472 rows x 106 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data and drop index\n",
    "beer_df = pd.read_csv('beer_data_9-13_for_classification.csv')\n",
    "beer_df.info()\n",
    "beer_df.head()\n",
    "beer_df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing it at this time helps to avoid overfitting or picking the wrong architecture based on bias\n",
    "#function for test set and validation set creation:\n",
    "def split_train_val_test(beer_df,validation_ratio, test_ratio):\n",
    "    np.random.seed(33)\n",
    "    shuffled_indices = np.random.permutation(len(beer_df))  #shuffles the dataset\n",
    "    validation_set_size = int(len(beer_df) * validation_ratio) #calculates validation set size based on ratio   \n",
    "    test_set_size = int(len(beer_df) * test_ratio) #calculates test size based on ratio\n",
    "    val_indices = shuffled_indices[:validation_set_size]\n",
    "    test_indices = shuffled_indices[:test_set_size] #selects test set and from incdices\n",
    "    train_indices = shuffled_indices[(test_set_size+validation_set_size):] #assigns the rest to training\n",
    "    return beer_df.iloc[train_indices], beer_df.iloc[val_indices], beer_df.iloc[test_indices] #returns two different dfs for test and train\n",
    "    \n",
    "#Using the function\n",
    "train_set, validation_set, test_set = split_train_val_test(beer_df, 0.15,0.10) #75% used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70105 14020 9347\n"
     ]
    }
   ],
   "source": [
    "#check that it worked\n",
    "print(len(train_set), len(validation_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "validation_set.to_csv('beer_data_val.csv')\n",
    "train_set.to_csv('beer_data_train.csv')\n",
    "test_set.to_csv('beer_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,normalize, Normalizer,LabelEncoder, OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding is the same as it was for clustering, except the target variables (Category) will be label encoded this time\n",
    "X = train_set.drop(['Unnamed: 0','Category'],axis=1)\n",
    "y = train_set[\"Category\"].copy()\n",
    "#variables with over 50% NaN/Missing values are categorized as \"highna\"\n",
    "num_highna=['mashph','hop2amount','hop2alpha','hop2time','hop2ibu',\n",
    "            'hop2percent','hop3amount','hop3alpha','hop3time',\n",
    "            'hop3ibu','hop3percent','hop4amount','hop4alpha',\n",
    "            'hop4time','hop4ibu','hop4percent','hop5amount',\n",
    "            'hop5alpha','hop5time','hop5ibu','hop5percent',\n",
    "            'Adjunct1Num','Adjunct2Num','Adjunct3Num','Adjunct4Num','Adjunct5Num']\n",
    "num_lowna = ['Batch_size_liters', 'og', 'fg', 'abv', 'ibu', 'color_levibonds',\n",
    "       'Base Malt Amount', 'BasePPG', 'BaseColor', 'BasePercentage',\n",
    "       'SpecialtyMalt1Amount', 'SpecialtyMalt1PPG', 'SpecialtyMalt1Color',\n",
    "       'SpecialtyMalt1Percentage', 'SpecialtyMalt2Amount', 'SpecialtyMalt2PPG',\n",
    "       'SpecialtyMalt2Color', 'SpecialtyMalt2Percentage',\n",
    "       'SpecialtyMalt3Amount', 'SpecialtyMalt3PPG', 'SpecialtyMalt3Color',\n",
    "       'SpecialtyMalt3Percentage','hop1amount','hop1time','hop1ibu','hop1percent','hop1alpha','Attenuation', 'LowTemp', 'HighTemp']\n",
    "cat_highna = ['hop2name', 'hop2type', 'hop2timing', 'hop3name',\n",
    "       'hop3type', 'hop3timing', 'hop4name', 'hop4type', 'hop4timing',\n",
    "       'hop5name', 'hop5type', 'hop5timing', 'Adjunct1Amount', 'Adjunct1Name', 'Adjunct1Type',\n",
    "       'Adjunct1Timing', 'Adjunct2Amount', 'Adjunct2Name', 'Adjunct2Type',\n",
    "       'Adjunct2Timing', 'Adjunct3Amount', 'Adjunct3Name', 'Adjunct3Type',\n",
    "       'Adjunct3Timing', 'Adjunct4Amount', 'Adjunct4Name', 'Adjunct4Type',\n",
    "       'Adjunct4Timing', 'Adjunct5Amount', 'Adjunct5Name', 'Adjunct5Type',\n",
    "       'Adjunct5Timing', 'Adjunct1Unit', 'Adjunct2Unit', 'Adjunct3Unit',\n",
    "       'Adjunct4Unit', 'Adjunct5Unit']\n",
    "cat_lowna = ['Batch_Style', 'Base Malt', 'SpecialtyMalt1Name',\n",
    "       'SpecialtyMalt2Name', 'SpecialtyMalt3Name', 'hop1name', 'hop1type',\n",
    "       'hop1timing', 'YeastStrain', 'Flocculation',\n",
    "       'Starter?', 'Flag']\n",
    "target = ['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles numerical values, imputing the mean and scaling (standard instead of minmax since it handles outliers better)\n",
    "num_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(weights='distance')),\n",
    "        ('standardizer', RobustScaler())\n",
    "    ])\n",
    "num_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"constant\",fill_value=0)),\n",
    "        ('standardizer', RobustScaler())\n",
    "    ])\n",
    "#handles categorical values, imputing the most frequent and onehot encoding\n",
    "cat_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('encoder', BinaryEncoder())        \n",
    "    ])\n",
    "cat_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        ('encoder', BinaryEncoder())\n",
    "    ])\n",
    "#pulls together two pipelines\n",
    "pre_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_lowna\", num_pipeline_lowna, num_lowna),\n",
    "        (\"num_highna\", num_pipeline_highna,num_highna),\n",
    "        (\"cat_lowna\", cat_pipeline_lowna, cat_lowna),\n",
    "        (\"cat_highna\", cat_pipeline_highna, cat_highna),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "beer_prepared = pre_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encodes the target variable\n",
    "le = LabelEncoder()\n",
    "label_encoder = le.fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out a few base models before we get to hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.987678565218786"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "style_predictions = lin_reg.predict(beer_prepared)\n",
    "lin_mse = mean_squared_error(y, style_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3167573384603923"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_predictions = tree_reg.predict(beer_prepared)\n",
    "tree_mse = mean_squared_error(y, style_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, beer_prepared, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display scores of various models using cross validation\n",
    "def display_scores(scores):\n",
    "     print(\"Scores:\", scores)\n",
    "     print(\"Mean:\", scores.mean())\n",
    "     print(\"Standard deviation:\", scores.std())\n",
    "display_scores(-scores)\n",
    "#this one is massively overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [43.96113548 44.40221072 44.02796973 44.53668452 44.33212676 44.81514152\n",
      " 44.02195562 44.43758537 43.86106308 44.47989823]\n",
      "Mean: 44.28757710244766\n",
      "Standard deviation: 0.2900729655918983\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "#not great but not as overfit as the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the base models for now in case I need em\n",
    "import joblib\n",
    "joblib.dump(lin_reg, \"base_lin_reg.pkl\")\n",
    "joblib.dump(tree_reg, \"base_decision_tree.pkl\")\n",
    "joblib.dump(forest_reg, \"base_random_forest.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
