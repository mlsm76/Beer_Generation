{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Units and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import category_encoders as ce\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "# Classification\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (26,39,40,42,47,48,50,55,56,58,63,64,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96540 entries, 0 to 96539\n",
      "Columns: 106 entries, Batch_Style to Flag\n",
      "dtypes: float64(55), int64(1), object(50)\n",
      "memory usage: 78.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Style</th>\n",
       "      <th>Category</th>\n",
       "      <th>Batch_size_liters</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color_levibonds</th>\n",
       "      <th>mashph</th>\n",
       "      <th>Base Malt Amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Adjunct1Unit</th>\n",
       "      <th>Adjunct2Num</th>\n",
       "      <th>Adjunct2Unit</th>\n",
       "      <th>Adjunct3Num</th>\n",
       "      <th>Adjunct3Unit</th>\n",
       "      <th>Adjunct4Num</th>\n",
       "      <th>Adjunct4Unit</th>\n",
       "      <th>Adjunct5Num</th>\n",
       "      <th>Adjunct5Unit</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Standard/Ordinary Bitter</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.008</td>\n",
       "      <td>4.31</td>\n",
       "      <td>25.98</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Belgian Dubbel</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.027</td>\n",
       "      <td>11.83</td>\n",
       "      <td>13.47</td>\n",
       "      <td>9.20</td>\n",
       "      <td>5.35</td>\n",
       "      <td>300.000</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partial Mash</td>\n",
       "      <td>Robust Porter</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.077</td>\n",
       "      <td>1.015</td>\n",
       "      <td>8.11</td>\n",
       "      <td>14.06</td>\n",
       "      <td>25.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.012</td>\n",
       "      <td>6.76</td>\n",
       "      <td>33.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Blonde Ale</td>\n",
       "      <td>1589.9</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.012</td>\n",
       "      <td>5.28</td>\n",
       "      <td>17.47</td>\n",
       "      <td>4.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.476</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96535</th>\n",
       "      <td>Extract</td>\n",
       "      <td>Mixed-Fermentation Sour Beer</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.011</td>\n",
       "      <td>5.11</td>\n",
       "      <td>9.59</td>\n",
       "      <td>5.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96536</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.010</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.268</td>\n",
       "      <td>...</td>\n",
       "      <td>tsp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96537</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Berliner Weisse</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.722</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Imperial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96538</th>\n",
       "      <td>BIAB</td>\n",
       "      <td>Weissbier</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.051</td>\n",
       "      <td>1.013</td>\n",
       "      <td>5.06</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96539</th>\n",
       "      <td>All Grain</td>\n",
       "      <td>Experimental Beer</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.023</td>\n",
       "      <td>6.10</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93473 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Batch_Style                       Category  Batch_size_liters     og  \\\n",
       "0          All Grain       Standard/Ordinary Bitter              480.0  1.041   \n",
       "1          All Grain                 Belgian Dubbel             1800.0  1.117   \n",
       "2       Partial Mash                  Robust Porter               20.8  1.077   \n",
       "3          All Grain                   American IPA              200.0  1.064   \n",
       "4          All Grain                     Blonde Ale             1589.9  1.053   \n",
       "...              ...                            ...                ...    ...   \n",
       "96535        Extract   Mixed-Fermentation Sour Beer               20.8  1.050   \n",
       "96536      All Grain                      Weissbier               19.9  1.051   \n",
       "96537           BIAB                Berliner Weisse               20.8  1.053   \n",
       "96538           BIAB                      Weissbier               50.0  1.051   \n",
       "96539      All Grain              Experimental Beer               20.0  1.069   \n",
       "\n",
       "          fg    abv    ibu  color_levibonds  mashph  Base Malt Amount  ...  \\\n",
       "0      1.008   4.31  25.98             3.00     NaN            75.000  ...   \n",
       "1      1.027  11.83  13.47             9.20    5.35           300.000  ...   \n",
       "2      1.015   8.11  14.06            25.81     NaN             0.454  ...   \n",
       "3      1.012   6.76  33.79            13.53     NaN            43.000  ...   \n",
       "4      1.012   5.28  17.47             4.08     NaN           249.476  ...   \n",
       "...      ...    ...    ...              ...     ...               ...  ...   \n",
       "96535  1.011   5.11   9.59             5.62     NaN             2.268  ...   \n",
       "96536  1.010   5.46   1.30             3.67    5.35             2.268  ...   \n",
       "96537  1.013   5.24   6.83             3.81     NaN             2.722  ...   \n",
       "96538  1.013   5.06   6.49             3.22     NaN             4.000  ...   \n",
       "96539  1.023   6.10  13.99             3.89    5.40             3.300  ...   \n",
       "\n",
       "      Adjunct1Unit  Adjunct2Num  Adjunct2Unit  Adjunct3Num  Adjunct3Unit  \\\n",
       "0              NaN          NaN           NaN          NaN           NaN   \n",
       "1                g          NaN           NaN          NaN           NaN   \n",
       "2              NaN          NaN           NaN          NaN           NaN   \n",
       "3              NaN          NaN           NaN          NaN           NaN   \n",
       "4              NaN          NaN           NaN          NaN           NaN   \n",
       "...            ...          ...           ...          ...           ...   \n",
       "96535          NaN          NaN           NaN          NaN           NaN   \n",
       "96536          tsp          NaN           NaN          NaN           NaN   \n",
       "96537          NaN          NaN           NaN          NaN           NaN   \n",
       "96538          NaN          NaN           NaN          NaN           NaN   \n",
       "96539          NaN          NaN           NaN          NaN           NaN   \n",
       "\n",
       "      Adjunct4Num  Adjunct4Unit  Adjunct5Num  Adjunct5Unit      Flag  \n",
       "0             NaN           NaN          NaN           NaN    Metric  \n",
       "1             NaN           NaN          NaN           NaN    Metric  \n",
       "2             NaN           NaN          NaN           NaN  Imperial  \n",
       "3             NaN           NaN          NaN           NaN    Metric  \n",
       "4             NaN           NaN          NaN           NaN  Imperial  \n",
       "...           ...           ...          ...           ...       ...  \n",
       "96535         NaN           NaN          NaN           NaN  Imperial  \n",
       "96536         NaN           NaN          NaN           NaN  Imperial  \n",
       "96537         NaN           NaN          NaN           NaN  Imperial  \n",
       "96538         NaN           NaN          NaN           NaN    Metric  \n",
       "96539         NaN           NaN          NaN           NaN    Metric  \n",
       "\n",
       "[93473 rows x 106 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data and drop index\n",
    "beer_df = pd.read_csv('beer_df_for_classification.csv',index_col=[0])\n",
    "beer_df.info()\n",
    "beer_df.head()\n",
    "beer_df.dropna(subset=['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing it at this time helps to avoid overfitting or picking the wrong architecture based on bias\n",
    "#function for test set and validation set creation:\n",
    "def split_train_val_test(beer_df,validation_ratio, test_ratio):\n",
    "    np.random.seed(33)\n",
    "    shuffled_indices = np.random.permutation(len(beer_df))  #shuffles the dataset\n",
    "    validation_set_size = int(len(beer_df) * validation_ratio) #calculates validation set size based on ratio   \n",
    "    test_set_size = int(len(beer_df) * test_ratio) #calculates test size based on ratio\n",
    "    val_indices = shuffled_indices[:validation_set_size]\n",
    "    test_indices = shuffled_indices[:test_set_size] #selects test set and from incdices\n",
    "    train_indices = shuffled_indices[(test_set_size+validation_set_size):] #assigns the rest to training\n",
    "    return beer_df.iloc[train_indices], beer_df.iloc[val_indices], beer_df.iloc[test_indices] #returns two different dfs for test and train\n",
    "    \n",
    "#Using the function\n",
    "train_set, validation_set, test_set = split_train_val_test(beer_df, 0.15,0.10) #75% used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72405 14481 9654\n"
     ]
    }
   ],
   "source": [
    "#check that it worked\n",
    "print(len(train_set), len(validation_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "validation_set.to_csv('beer_data_val.csv')\n",
    "train_set.to_csv('beer_data_train.csv')\n",
    "test_set.to_csv('beer_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,normalize, Normalizer,LabelEncoder, OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder\n",
    "from category_encoders.count import CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70057\n"
     ]
    }
   ],
   "source": [
    "train_set = train_set.dropna(subset=['Category'])\n",
    "X = train_set.drop(['Category'],axis=1)\n",
    "y = train_set[\"Category\"].copy()\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding is the same as it was for clustering, except the target variables (Category) will be label encoded this time\n",
    "#variables with over 50% NaN/Missing values are categorized as \"highna\"\n",
    "num_highna=['mashph','hop2amount','hop2alpha','hop2time','hop2ibu',\n",
    "            'hop2percent','hop3amount','hop3alpha','hop3time',\n",
    "            'hop3ibu','hop3percent','hop4amount','hop4alpha',\n",
    "            'hop4time','hop4ibu','hop4percent','hop5amount',\n",
    "            'hop5alpha','hop5time','hop5ibu','hop5percent',\n",
    "            'Adjunct1Num','Adjunct2Num','Adjunct3Num','Adjunct4Num','Adjunct5Num']\n",
    "num_lowna = ['Batch_size_liters', 'og', 'fg', 'abv', 'ibu', 'color_levibonds',\n",
    "       'Base Malt Amount', 'BasePPG', 'BaseColor', 'BasePercentage',\n",
    "       'SpecialtyMalt1Amount', 'SpecialtyMalt1PPG', 'SpecialtyMalt1Color',\n",
    "       'SpecialtyMalt1Percentage', 'SpecialtyMalt2Amount', 'SpecialtyMalt2PPG',\n",
    "       'SpecialtyMalt2Color', 'SpecialtyMalt2Percentage',\n",
    "       'SpecialtyMalt3Amount', 'SpecialtyMalt3PPG', 'SpecialtyMalt3Color',\n",
    "       'SpecialtyMalt3Percentage','hop1amount','hop1time','hop1ibu','hop1percent','hop1alpha','Attenuation', 'LowTemp', 'HighTemp']\n",
    "cat_highna = ['hop2name', 'hop2type', 'hop2timing', 'hop3name',\n",
    "       'hop3type', 'hop3timing', 'hop4name', 'hop4type', 'hop4timing',\n",
    "       'hop5name', 'hop5type', 'hop5timing', 'Adjunct1Amount', 'Adjunct1Name', 'Adjunct1Type',\n",
    "       'Adjunct1Timing', 'Adjunct2Amount', 'Adjunct2Name', 'Adjunct2Type',\n",
    "       'Adjunct2Timing', 'Adjunct3Amount', 'Adjunct3Name', 'Adjunct3Type',\n",
    "       'Adjunct3Timing', 'Adjunct4Amount', 'Adjunct4Name', 'Adjunct4Type',\n",
    "       'Adjunct4Timing', 'Adjunct5Amount', 'Adjunct5Name', 'Adjunct5Type',\n",
    "       'Adjunct5Timing', 'Adjunct1Unit', 'Adjunct2Unit', 'Adjunct3Unit',\n",
    "       'Adjunct4Unit', 'Adjunct5Unit']\n",
    "cat_lowna = ['Batch_Style', 'Base Malt', 'SpecialtyMalt1Name',\n",
    "       'SpecialtyMalt2Name', 'SpecialtyMalt3Name', 'hop1name', 'hop1type',\n",
    "       'hop1timing', 'YeastStrain', 'Flocculation',\n",
    "       'Starter?', 'Flag']\n",
    "target = ['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles numerical values, imputing the mean and scaling (standard instead of minmax since it handles outliers better)\n",
    "num_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"mean\")),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "num_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"constant\",fill_value=0)),\n",
    "        ('standardizer', RobustScaler(with_centering=False))\n",
    "    ])\n",
    "#handles categorical values, imputing the most frequent and onehot encoding\n",
    "cat_pipeline_lowna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")),\n",
    "        ('encoder', TargetEncoder(handle_missing='return_nan',min_samples_leaf=100,smoothing=10)),\n",
    "        ('standardizer', RobustScaler())\n",
    "       \n",
    "    ])\n",
    "cat_pipeline_highna = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"most_frequent\")),\n",
    "        ('encoder', TargetEncoder(handle_missing='return_nan',min_samples_leaf=100,smoothing=10)),\n",
    "        ('standardizer', RobustScaler())\n",
    "    ])\n",
    "#pulls together two pipelines\n",
    "pre_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_lowna\", num_pipeline_lowna, num_lowna),\n",
    "        (\"num_highna\", num_pipeline_highna,num_highna),\n",
    "        (\"cat_lowna\", cat_pipeline_lowna, cat_lowna),\n",
    "        (\"cat_highna\", cat_pipeline_highna, cat_highna),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encodes the target variable\n",
    "le = LabelEncoder()\n",
    "label_encoder = le.fit(y)\n",
    "y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\mitch\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "beer_prepared = pre_pipeline.fit_transform(X,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70057"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out a few base models before we get to hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.442771480228174"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "style_predictions = lin_reg.predict(beer_prepared)\n",
    "lin_mse = mean_squared_error(y, style_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22149503629031086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_predictions = tree_reg.predict(beer_prepared)\n",
    "tree_mse = mean_squared_error(y, style_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, beer_prepared, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [2882.03786041 2904.907829   2718.16575079 2812.75977733 2942.99414787\n",
      " 2860.86168998 2947.34727377 2823.39700214 2745.92633833 2866.76745182]\n",
      "Mean: 2850.5165121437667\n",
      "Standard deviation: 72.710592993121\n"
     ]
    }
   ],
   "source": [
    "#function to display scores of various models using cross validation\n",
    "def display_scores(scores):\n",
    "     print(\"Scores:\", scores)\n",
    "     print(\"Mean:\", scores.mean())\n",
    "     print(\"Standard deviation:\", scores.std())\n",
    "display_scores(-scores)\n",
    "#this one is massively overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 41.25313864  41.68320675  41.43610998  41.63630872  41.78240718\n",
      "  41.96375986  41.39615871 135.04085334  40.70116613  41.45458071]\n",
      "Mean: 50.83476900221565\n",
      "Standard deviation: 28.070580854932803\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "#not great but not as overfit as the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [37.1862683  37.58172514 37.48675662 37.3825078  38.18165039 37.82251424\n",
      " 37.8917524  38.03902301 36.70879563 37.56284486]\n",
      "Mean: 37.58438383949072\n",
      "Standard deviation: 0.4111584030818157\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, beer_prepared, y,\n",
    "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_random_forest.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the base models for now in case I need em\n",
    "import joblib\n",
    "joblib.dump(lin_reg, \"base_lin_reg.pkl\")\n",
    "joblib.dump(tree_reg, \"base_decision_tree.pkl\")\n",
    "joblib.dump(forest_reg, \"base_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [20, 40, 60, 80],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [20, 30, 40],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [20, 40, 60, 80]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [20, 30, 40]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(beer_prepared, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=60, n_estimators=30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02155604e-02, 2.23697723e-02, 1.62397973e-02, 3.37825604e-02,\n",
       "       4.14059720e-02, 5.98098967e-02, 1.29447237e-02, 6.99118075e-03,\n",
       "       1.07268040e-02, 1.74293673e-02, 1.17202696e-02, 9.29929712e-03,\n",
       "       1.42525095e-02, 1.67876484e-02, 9.31572802e-03, 8.87325606e-03,\n",
       "       1.25584937e-02, 1.32524497e-02, 7.95099064e-03, 7.56034474e-03,\n",
       "       9.44153697e-03, 1.11053021e-02, 1.13729516e-02, 6.40677246e-03,\n",
       "       1.93145805e-02, 1.51994116e-02, 1.35893076e-02, 1.08057369e-02,\n",
       "       1.18082729e-02, 1.11250883e-02, 5.21349620e-03, 7.16020408e-03,\n",
       "       1.30459836e-02, 1.66427293e-03, 2.44338950e-03, 3.39147846e-03,\n",
       "       1.26153243e-03, 3.02940034e-03, 1.02452402e-03, 1.11290586e-03,\n",
       "       1.68712982e-03, 6.21774280e-04, 9.53388170e-04, 5.74459886e-04,\n",
       "       5.72254281e-04, 8.11625913e-04, 4.82184303e-04, 4.83098146e-04,\n",
       "       4.82423848e-04, 3.28703031e-04, 5.57937033e-04, 1.44892684e-03,\n",
       "       1.19037660e-03, 1.37006533e-03, 5.91859549e-04, 6.80824036e-04,\n",
       "       2.90034795e-03, 2.25762257e-02, 2.11229598e-02, 1.73341765e-02,\n",
       "       1.25399577e-02, 3.64549245e-02, 1.76137961e-03, 1.02364087e-03,\n",
       "       2.40317964e-01, 1.41691787e-02, 1.87383614e-03, 1.00842759e-03,\n",
       "       7.92685085e-02, 6.14945384e-04, 1.13881730e-03, 4.06941522e-03,\n",
       "       3.57645626e-04, 5.35264261e-04, 7.49455698e-04, 1.66137256e-04,\n",
       "       2.02821206e-04, 4.22373665e-04, 1.94957887e-04, 1.93289535e-04,\n",
       "       1.84949700e-03, 1.20336143e-03, 2.69851598e-04, 5.79543261e-04,\n",
       "       1.48478460e-03, 1.68553142e-03, 5.01513984e-04, 9.16170652e-04,\n",
       "       1.63561100e-03, 1.37549508e-03, 6.85890775e-04, 9.93658821e-04,\n",
       "       7.57467140e-04, 7.67246870e-04, 6.36468509e-04, 6.24574956e-04,\n",
       "       1.35962962e-03, 4.98879018e-04, 3.92539189e-04, 5.56203512e-04,\n",
       "       9.64471447e-04, 1.02964639e-03, 9.47191610e-04, 4.53715890e-04,\n",
       "       9.94604173e-04])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457.2149536057655 38.17348495494963\n"
     ]
    }
   ],
   "source": [
    "#cat_high = pre_pipeline.named_transformers_[\"cat_highna\"]\n",
    "#cat_high_attribs = list(cat_high.components_)\n",
    "#cat_low = pre_pipeline.named_transformers_[\"cat_lowna\"]\n",
    "#Acat_low_attribs = list(cat_low.get_feature_names(input_features=cat_lowna))\n",
    "#attributes = num_highna + num_lowna + cat_low_attribs + cat_high_attribs\n",
    "#sorted(zip(feature_importances, attributes), reverse=True)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "test_set = test_set.dropna(subset=['Category'])\n",
    "X_test = test_set.drop('Category',axis=1)\n",
    "y = test_set['Category'].copy()\n",
    "y_test = le.transform(y)\n",
    "\n",
    "X_test_prepared = pre_pipeline.transform(X_test)\n",
    "\n",
    "model_preds = best_model.predict(X_test_prepared)\n",
    "\n",
    "model_mse = mean_squared_error(y_test, model_preds)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "\n",
    "print(model_mse,model_rmse) #rmse = 38.17, mse = 1457.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match up feature importances with actual names of features\n",
    "targetencode_cols_low = list(pre_pipeline.named_transformers_['cat_lowna'].named_steps['encoder'].get_feature_names())\n",
    "targetencode_cols_high = list(pre_pipeline.named_transformers_['cat_highna'].named_steps['encoder'].get_feature_names())\n",
    "numeric_list = list(num_lowna)\n",
    "numeric_highna_list = list(num_highna)\n",
    "numeric_list.extend(num_highna)\n",
    "numeric_list.extend(targetencode_cols_high)\n",
    "numeric_list.extend(targetencode_cols_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batch_size_liters',\n",
       " 'og',\n",
       " 'fg',\n",
       " 'abv',\n",
       " 'ibu',\n",
       " 'color_levibonds',\n",
       " 'Base Malt Amount',\n",
       " 'BasePPG',\n",
       " 'BaseColor',\n",
       " 'BasePercentage',\n",
       " 'SpecialtyMalt1Amount',\n",
       " 'SpecialtyMalt1PPG',\n",
       " 'SpecialtyMalt1Color',\n",
       " 'SpecialtyMalt1Percentage',\n",
       " 'SpecialtyMalt2Amount',\n",
       " 'SpecialtyMalt2PPG',\n",
       " 'SpecialtyMalt2Color',\n",
       " 'SpecialtyMalt2Percentage',\n",
       " 'SpecialtyMalt3Amount',\n",
       " 'SpecialtyMalt3PPG',\n",
       " 'SpecialtyMalt3Color',\n",
       " 'SpecialtyMalt3Percentage',\n",
       " 'hop1amount',\n",
       " 'hop1time',\n",
       " 'hop1ibu',\n",
       " 'hop1percent',\n",
       " 'hop1alpha',\n",
       " 'Attenuation',\n",
       " 'LowTemp',\n",
       " 'HighTemp',\n",
       " 'mashph',\n",
       " 'hop2amount',\n",
       " 'hop2alpha',\n",
       " 'hop2time',\n",
       " 'hop2ibu',\n",
       " 'hop2percent',\n",
       " 'hop3amount',\n",
       " 'hop3alpha',\n",
       " 'hop3time',\n",
       " 'hop3ibu',\n",
       " 'hop3percent',\n",
       " 'hop4amount',\n",
       " 'hop4alpha',\n",
       " 'hop4time',\n",
       " 'hop4ibu',\n",
       " 'hop4percent',\n",
       " 'hop5amount',\n",
       " 'hop5alpha',\n",
       " 'hop5time',\n",
       " 'hop5ibu',\n",
       " 'hop5percent',\n",
       " 'Adjunct1Num',\n",
       " 'Adjunct2Num',\n",
       " 'Adjunct3Num',\n",
       " 'Adjunct4Num',\n",
       " 'Adjunct5Num',\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
